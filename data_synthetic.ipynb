{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Synthetic sales_data.csv\n",
    "def generate_sales_data(num_records=1000):\n",
    "    fake = Faker()\n",
    "    Faker.seed(0)\n",
    "    \n",
    "    product_ids = [f\"P{i:03d}\" for i in range(1, 21)]  # 20 product IDs\n",
    "    customer_ids = [f\"C{i:03d}\" for i in range(1, 51)]  # 50 customer IDs\n",
    "    \n",
    "    data = {\n",
    "        \"order_id\": [],\n",
    "        \"order_date\": [],\n",
    "        \"product_id\": [],\n",
    "        \"quantity\": [],\n",
    "        \"price\": [],\n",
    "        \"customer_id\": []\n",
    "    }\n",
    "    \n",
    "    for i in range(num_records):\n",
    "        data[\"order_id\"].append(i+1)\n",
    "        data[\"order_date\"].append(fake.date_between(start_date=\"-2y\", end_date=\"today\"))\n",
    "        data[\"product_id\"].append(random.choice(product_ids))\n",
    "        data[\"quantity\"].append(random.randint(1, 10))\n",
    "        data[\"price\"].append(round(random.uniform(5, 200), 2))\n",
    "        data[\"customer_id\"].append(random.choice(customer_ids))\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    # Sort by date if desired\n",
    "    df.sort_values(\"order_date\", inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "sales_df = generate_sales_data(num_records=1000)\n",
    "sales_df.to_csv(\"data/sales_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Join data\n",
    "def generate_user_data(num_users=100):\n",
    "    fake = Faker()\n",
    "    Faker.seed(0)\n",
    "    \n",
    "    # Possible categories\n",
    "    genders = [\"Male\", \"Female\", \"Non-Binary\"]\n",
    "    countries = [\"USA\", \"Canada\", \"UK\", \"Germany\", \"France\", \"Australia\"]\n",
    "    \n",
    "    demo_data = {\n",
    "        \"user_id\": [],\n",
    "        \"age\": [],\n",
    "        \"gender\": [],\n",
    "        \"country\": []\n",
    "    }\n",
    "    \n",
    "    for i in range(num_users):\n",
    "        user_id = f\"U{i+1:04d}\"\n",
    "        demo_data[\"user_id\"].append(user_id)\n",
    "        demo_data[\"age\"].append(random.randint(18, 70))\n",
    "        demo_data[\"gender\"].append(random.choice(genders))\n",
    "        demo_data[\"country\"].append(random.choice(countries))\n",
    "    \n",
    "    user_demographics_df = pd.DataFrame(demo_data)\n",
    "    \n",
    "    # Generate interactions (potentially more than one per user)\n",
    "    interaction_types = [\"view\", \"click\", \"purchase\"]\n",
    "    num_records = num_users * 5  # average 5 interactions per user\n",
    "    interaction_data = {\n",
    "        \"user_id\": [],\n",
    "        \"interaction_type\": [],\n",
    "        \"item_id\": [],\n",
    "        \"timestamp\": []\n",
    "    }\n",
    "    \n",
    "    for _ in range(num_records):\n",
    "        user_id = random.choice(demo_data[\"user_id\"])\n",
    "        interaction_data[\"user_id\"].append(user_id)\n",
    "        interaction_data[\"interaction_type\"].append(random.choice(interaction_types))\n",
    "        interaction_data[\"item_id\"].append(f\"Item_{random.randint(1, 50)}\")\n",
    "        interaction_data[\"timestamp\"].append(fake.date_time_between(start_date=\"-1y\", end_date=\"now\"))\n",
    "    \n",
    "    user_interactions_df = pd.DataFrame(interaction_data)\n",
    "    # Sort by timestamp\n",
    "    user_interactions_df.sort_values(\"timestamp\", inplace=True)\n",
    "    user_interactions_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return user_interactions_df, user_demographics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui_df, ud_df = generate_user_data(num_users=100)\n",
    "ui_df.to_csv(\"data/user_interactions.csv\", index=False)\n",
    "ud_df.to_csv(\"data/user_demographics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Synthetic Housing Data\n",
    "\n",
    "def generate_housing_data(num_records=200, missing_rate=0.1):\n",
    "    locations = [\"Downtown\", \"Suburbs\", \"Countryside\", \"Beachside\"]\n",
    "    \n",
    "    data = {\n",
    "        \"house_id\": [],\n",
    "        \"num_rooms\": [],\n",
    "        \"num_bathrooms\": [],\n",
    "        \"square_feet\": [],\n",
    "        \"location\": [],\n",
    "        \"price\": []\n",
    "    }\n",
    "    \n",
    "    for i in range(num_records):\n",
    "        data[\"house_id\"].append(f\"H{i+1:04d}\")\n",
    "        \n",
    "        # Some values may be missing\n",
    "        if random.random() < missing_rate:\n",
    "            num_rooms = None\n",
    "        else:\n",
    "            num_rooms = random.uniform(1, 5)  # could be 1.0, 2.5, etc.\n",
    "        data[\"num_rooms\"].append(num_rooms)\n",
    "        \n",
    "        if random.random() < missing_rate:\n",
    "            num_bathrooms = None\n",
    "        else:\n",
    "            num_bathrooms = random.uniform(1, 3)\n",
    "        data[\"num_bathrooms\"].append(num_bathrooms)\n",
    "        \n",
    "        data[\"square_feet\"].append(random.randint(600, 4000))\n",
    "        data[\"location\"].append(random.choice(locations))\n",
    "        data[\"price\"].append(random.uniform(100000, 1000000))  # from 100k to 1M\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_df = generate_housing_data(num_records=1000)\n",
    "houses_df.to_csv(\"data/houses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Synthetic Stock Data\n",
    "def generate_stock_data(num_days=200):\n",
    "    fake = Faker()\n",
    "    Faker.seed(0)\n",
    "    \n",
    "    tickers = [\"AAPL\", \"MSFT\", \"GOOG\", \"TSLA\", \"AMZN\"]\n",
    "    \n",
    "    dates = pd.date_range(start=\"2023-01-01\", periods=num_days, freq=\"D\")\n",
    "    data = {\n",
    "        \"date\": [],\n",
    "        \"ticker\": [],\n",
    "        \"close_price\": []\n",
    "    }\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        price = random.uniform(100, 300)  # starting price\n",
    "        for d in dates:\n",
    "            # simulate day-to-day price changes\n",
    "            price *= random.uniform(0.98, 1.02)  \n",
    "            data[\"date\"].append(d)\n",
    "            data[\"ticker\"].append(ticker)\n",
    "            data[\"close_price\"].append(round(price, 2))\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df.sort_values([\"ticker\", \"date\"], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df = generate_stock_data(num_days=1000)\n",
    "stock_df.to_csv(\"data/stock_prices.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
